{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "## Learning Objectives:\n",
    "1. How to prepare data for machine learning, i.e., feature selection\n",
    "1. How to learn a machine learning classifier\n",
    "1. How to learn a machine learning classifier\n",
    "1. How to apply a machine learning classifier\n",
    "1. How to evaluate a machine learning classifier\n",
    "\n",
    "### Process:\n",
    "1. load dataset\n",
    "1. analyzse dataset\n",
    "1. create feature vector\n",
    "1. vectorize data\n",
    "1. learn machine learning classifier\n",
    "1. evaluate classifier\n",
    "1. apply machine learning classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install xlrd\n",
    "!{sys.executable} -m pip install nltk\n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "!{sys.executable} -m pip install scipy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################\n",
    "# Required\n",
    "################################\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "\n",
    "# Feature Creation\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#tokenizer = RegexpTokenizer(r'\\w+[-]?\\w+')\n",
    "\n",
    "# Machine Learning Algorithms\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# More at http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "################################\n",
    "# Optional\n",
    "################################\n",
    "import re #RegEx\n",
    "\n",
    "# Improve feature creation\n",
    "## Natural Language Processing module\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Improve feature selection\n",
    "import sklearn\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Machine Learning\n",
    "import scipy\n",
    "from scipy.sparse import dok_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking versions\n",
    "print('Version check:\\n--------------')\n",
    "print('Pandas v',pd.__version__)\n",
    "print('NLTK v',nltk.__version__)\n",
    "print('SKLearn v',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to download NLTK packages\n",
    "Replace *URL*, *USERNAME*, and *PASSWORD* if you need to configure a proxy.\n",
    "\n",
    "Then, uncomment the lines and run it.\n",
    "\n",
    "*Please note that a separate windows will popup. Select the appropriate package.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.set_proxy('http://gate-zrh-os.swissre.com:8080', ('<USERNAME>', '<PASSWORD>'))\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving DataFrame as EXCEL for review\n",
    "def writeResults(dfResults, sFilename, sPrefix='', sPostfix=''):\n",
    "    fnOut = sFilename\n",
    "    if sPrefix:\n",
    "        fnOut = sPrefix + fnOut\n",
    "    if sPostfix:\n",
    "        fnOut = fnOut + sPostfix\n",
    "        \n",
    "    filepath = outDirectory + fnOut\n",
    "    dfResults.to_excel(filepath)\n",
    "    print('Results haven been written to ', filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath to dataset\n",
    "fpDataset = './data/customer-feedback_full_cleaned_1000.xlsx'\n",
    "\n",
    "#Load Excel file into a DataFrame\n",
    "dfExcelWorkbook = pd.read_excel(fpDataset, sheet_name=None)\n",
    "sheets = list(dfExcelWorkbook.keys())\n",
    "dfData = dfExcelWorkbook[sheets[0]]\n",
    "\n",
    "# Prepare directory to output results\n",
    "outDirectory = './result/'\n",
    "if not os.path.exists(outDirectory):\n",
    "    os.makedirs(outDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset \n",
    "dfData.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats and Infos\n",
    "Some info about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of attributes:', dfData.shape[1])\n",
    "print('Name of attributes:', dfData.columns)\n",
    "print('Number of rows:', dfData.shape[0])\n",
    "print('Positives/Negatives:', dfData['RATING'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feacture Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Feature Vector\n",
    "Machine learning requires that features (input) correlates with target class (output). For that reason, we need to define the features that we want to use for machine learning. We use words as features because they correlate with sentiments.\n",
    "\n",
    "### Result\n",
    "* **dfFeature**: DataFrame containing a list of features (words). It contains for each feature the frequency and avg. sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# MODIFY THIS METHOD TO WIN\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# HINT: e.g., TF/IDF\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "\n",
    "# counts the tokens in a list of tokens.\n",
    "def countTokens(tokens):\n",
    "    results = {}\n",
    "\n",
    "    for token in tokens:\n",
    "        if token not in results:\n",
    "            results[token] = 1\n",
    "        else:\n",
    "            results[token] = results[token] + 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# MODIFY THIS METHOD TO WIN\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# HINT: stopwords, lemmatization, stemming, named entity, lowercase, word combination (e.g, 'not good'), adjectives, etc. \n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "\n",
    "# extract features from a text\n",
    "def extractTokens(strText):\n",
    "    result = []\n",
    "    # features = tokenizer.tokenize(strText)\n",
    "    result = re.split('\\s', strText)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureColumns = ['feature', 'positives', 'negatives']\n",
    "dfFeatures = pd.DataFrame(columns=featureColumns)\n",
    "colFeedback = 'FEEDBACK'\n",
    "colRating = 'RATING'\n",
    "\n",
    "features = {}\n",
    "for index, row in dfData.iterrows():\n",
    "    # get feedback\n",
    "    feedback = dfData.iloc[index][colFeedback]\n",
    "    rating = dfData.iloc[index][colRating]\n",
    "    \n",
    "    # analyze feedback\n",
    "    tokens = extractTokens(str(feedback))\n",
    "    featurecount = countTokens(tokens)\n",
    "    \n",
    "    # add to feature list\n",
    "    for feature in featurecount.keys():\n",
    "        if feature not in features:\n",
    "            features[feature] = {'positives': 0, 'negatives': 0}\n",
    "        if rating == 0:\n",
    "            features[feature]['negatives'] = features[feature]['negatives'] + 1\n",
    "        elif rating != 0:\n",
    "            features[feature]['positives'] = features[feature]['positives'] + 1   \n",
    "          \n",
    "# create and beautify\n",
    "dfFeatures = pd.DataFrame.from_dict(features, orient='index')\n",
    "dfFeatures = dfFeatures.reset_index()\n",
    "dfFeatures = dfFeatures.rename({'index':'feature'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of times freature occures\n",
    "dfFeatures['support'] = dfFeatures.apply(lambda x: x['positives'] + x['negatives'], axis=1)\n",
    "\n",
    "# Compute sentiment value feature\n",
    "dfFeatures['sentiment'] = dfFeatures.apply(lambda x: x['positives'] / x['support'], axis=1)\n",
    "fnFeaturesAll = 'allfeatures.xlsx'\n",
    "writeResults(dfFeatures, fnFeaturesAll)\n",
    "\n",
    "dfFeatures.sort_values(by='support', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Features\", dfFeatures.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (i) DISCUSSION: How to clean up the features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExcelWorkbook = pd.read_excel(outDirectory + fnFeaturesAll, sheet_name=None)\n",
    "sheets = list(dfExcelWorkbook.keys())\n",
    "dfFeatures = dfExcelWorkbook[sheets[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Feature Stats:')\n",
    "print('Number of Features:', dfFeatures.shape[0])\n",
    "dfFeatures.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFeatureVector = dfFeatures.sort_values(by='support', ascending=False)\n",
    "dfFeatureVector.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top-10 Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFeatureVector.sort_values(by='sentiment', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-10 Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFeatureVector.sort_values(by='sentiment', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# MODIFY THIS METHOD TO WIN\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# HINT: e.g., remove rare features, remove irrelevant features\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "\n",
    "def selectFeatures(dfFeatures):\n",
    "    print(\"Number of features:\",dfFeatures.shape[0])\n",
    "    result = dfFeatures\n",
    "    # result = dfFeatures[dfFeatures.support > 10]\n",
    "    \n",
    "    print(\"Number of selected features:\", result.shape[0])\n",
    "    return result\n",
    "    \n",
    "dfSelectedFeatures = selectFeatures(dfFeatureVector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Trainingset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An instance from a text is used to train a machine learning model or to classify the text. The instance is a vector representation of a text based on the given feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createInstance(strText, dfFeatures=dfFeatureVector):\n",
    "    result = []\n",
    "    \n",
    "    for feature in dfFeatureVector['feature']:\n",
    "        if (str(feature) in strText):\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = []\n",
    "trainSetLabels = []\n",
    "for index, row in dfData.iterrows():\n",
    "    instance = createInstance(str(row['FEEDBACK']))\n",
    "    trainSet.append(instance)\n",
    "    trainSetLabels.append(row['RATING'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check result\n",
    "trainSet[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X2TrainInstances = SelectKBest(chi2, k=10).fit_transform(trainSet, trainSetLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = dok_matrix(trainSet)\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "myDecisionTree = DecisionTreeClassifier(max_depth=5)\n",
    "classifier = myDecisionTree.fit(trainSet,trainSetLabels)\n",
    "\n",
    "# Random Forest\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# classifier = RandomForestClassifier(n_estimators=20).fit(trainSet,trainSetLabels)\n",
    "\n",
    "# Naive Bayes (NB)\n",
    "# classifier = GaussianNB().fit(trainSet,trainSetLabels)\n",
    "\n",
    "# ADA Boost\n",
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "#classifier = AdaBoostClassifier(n_estimators=200).fit(m,trainSetLabels)\n",
    "\n",
    "# Support Vector Machines (SVM)\n",
    "# classifier = SVC().fit(m,trainSetLabels)\n",
    "\n",
    "# Neural Network (NN)\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#classifier = MLPClassifier(alpha=1).fit(trainSet,trainSetLabels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(trainSet,trainSetLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(myDecisionTree, trainSet, trainSetLabels, cv=10)\n",
    "print('Score per fold:', score)\n",
    "print('Avg. Score:', score.mean())\n",
    "\n",
    "Precision_score = cross_val_score(myDecisionTree, trainSet, trainSetLabels, cv=10, scoring='precision')\n",
    "print('Precision:', Precision_score.mean())\n",
    "Recall_score = cross_val_score(myDecisionTree, trainSet, trainSetLabels, cv=10, scoring='recall')\n",
    "print('Recall:', Recall_score.mean())\n",
    "F1_score = cross_val_score(myDecisionTree, trainSet, trainSetLabels, cv=10, scoring='f1')\n",
    "print('F1:', F1_score.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = myDecisionTree.fit(trainSet,trainSetLabels)\n",
    "\n",
    "# Naive Bayes (NB)\n",
    "#classifier = GaussianNB().fit(trainSet,trainSetLabels)\n",
    "\n",
    "# Support Vector Machines (SVM)\n",
    "# svm = SVC()\n",
    "# classifier = svm.fit(m,trainSetLabels)\n",
    "\n",
    "# ADA Boost\n",
    "# adaBoost = AdaBoostClassifier(n_estimators=200)\n",
    "# classifier = adaBoost.fit(m,trainSetLabels)\n",
    "\n",
    "# Random Forest\n",
    "# randomForest = RandomForestClassifier(n_estimat§ors=20)\n",
    "# classifier = randomForest.fit(trainSet,trainSetLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dfData[0:100].iterrows():\n",
    "    feedback = str(row['FEEDBACK'])\n",
    "    instance = [createInstance(feedback)]\n",
    "    predictedSentiment = classifier.predict(instance)\n",
    "    \n",
    "    if (predictedSentiment != row['RATING']):\n",
    "        sentiment = 'BAD'\n",
    "        if predictedSentiment == 1:\n",
    "            sentiment = 'GOOD'\n",
    "        print(\"AI says\", sentiment, \":\\t\",feedback)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
