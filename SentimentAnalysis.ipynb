{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "## Learning Objectives:\n",
    "1. How to prepare data for machine learning, i.e., feature selection\n",
    "1. How to learn a machine learning classifier\n",
    "1. How to learn a machine learning classifier\n",
    "1. How to apply a machine learning classifier\n",
    "1. How to evaluate a machine learning classifier\n",
    "\n",
    "### Process:\n",
    "1. load dataset\n",
    "1. analyzse dataset\n",
    "1. create feature vector\n",
    "1. vectorize data\n",
    "1. learn machine learning classifier\n",
    "1. evaluate classifier\n",
    "1. apply machine learning classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/bouza/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Users/bouza/anaconda3/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/bouza/anaconda3/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: python-dateutil>=2 in /Users/bouza/anaconda3/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: six>=1.5 in /Users/bouza/anaconda3/lib/python3.6/site-packages (from python-dateutil>=2->pandas)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: xlrd in /Users/bouza/anaconda3/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: nltk in /Users/bouza/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: six in /Users/bouza/anaconda3/lib/python3.6/site-packages (from nltk)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sklearn in /Users/bouza/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: scikit-learn in /Users/bouza/anaconda3/lib/python3.6/site-packages (from sklearn)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: openpyxl in /Users/bouza/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: jdcal in /Users/bouza/anaconda3/lib/python3.6/site-packages (from openpyxl)\n",
      "Requirement already satisfied: et_xmlfile in /Users/bouza/anaconda3/lib/python3.6/site-packages (from openpyxl)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scipy in /Users/bouza/anaconda3/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install xlrd\n",
    "!{sys.executable} -m pip install nltk\n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "!{sys.executable} -m pip install scipy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################\n",
    "# Required\n",
    "################################\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "\n",
    "# Feature Creation\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#tokenizer = RegexpTokenizer(r'\\w+[-]?\\w+')\n",
    "\n",
    "# Machine Learning Algorithms\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# More at http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "################################\n",
    "# Optional\n",
    "################################\n",
    "import re #RegEx\n",
    "\n",
    "# Improve feature creation\n",
    "## Natural Language Processing module\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Improve feature selection\n",
    "import sklearn\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Machine Learning\n",
    "import scipy\n",
    "from scipy.sparse import dok_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version check:\n",
      "--------------\n",
      "Pandas v 0.22.0\n",
      "NLTK v 3.2.4\n",
      "SKLearn v 0.19.1\n"
     ]
    }
   ],
   "source": [
    "# Checking versions\n",
    "print('Version check:\\n--------------')\n",
    "print('Pandas v',pd.__version__)\n",
    "print('NLTK v',nltk.__version__)\n",
    "print('SKLearn v',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to download NLTK packages\n",
    "Replace *URL*, *USERNAME*, and *PASSWORD* if you need to configure a proxy.\n",
    "\n",
    "Then, uncomment the lines and run it.\n",
    "\n",
    "*Please note that a separate windows will popup. Select the appropriate package.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.set_proxy('http://gate-zrh-os.swissre.com:8080', ('<USERNAME>', '<PASSWORD>'))\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving DataFrame as EXCEL for review\n",
    "def writeResults(dfResults, sFilename, sPrefix='', sPostfix=''):\n",
    "    fnOut = sFilename\n",
    "    if sPrefix:\n",
    "        fnOut = sPrefix + fnOut\n",
    "    if sPostfix:\n",
    "        fnOut = fnOut + sPostfix\n",
    "        \n",
    "    filepath = outDirectory + fnOut\n",
    "    dfResults.to_excel(filepath)\n",
    "    print('Results haven been written to ', filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath to dataset\n",
    "fpDataset = './data/customerfeedback.xlsx'\n",
    "\n",
    "#Load Excel file into a DataFrame\n",
    "dfExcelWorkbook = pd.read_excel(fpDataset, sheet_name=None)\n",
    "sheets = list(dfExcelWorkbook.keys())\n",
    "dfData = dfExcelWorkbook[sheets[0]]\n",
    "\n",
    "# Prepare directory to output results\n",
    "outDirectory = './result/'\n",
    "if not os.path.exists(outDirectory):\n",
    "    os.makedirs(outDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEEDBACK</th>\n",
       "      <th>RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never got clean glasses in Warsaw either.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The bed in the Radisson Bleu was not comfortab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michael was an excellent tour director. He wen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Krakow Hotel was below my expectations because...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All the city tour guides have been excellent a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The bed in the Radisson Bleu was not comfortab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Prague hotel should provide in-room intern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Michael (Tour Director) was brilliant! Thomas ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The entire voyage was very well done by Viking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Michael was excellent. The Prague hotel should...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            FEEDBACK  RATING\n",
       "0          never got clean glasses in Warsaw either.       0\n",
       "1  The bed in the Radisson Bleu was not comfortab...       1\n",
       "2  Michael was an excellent tour director. He wen...       1\n",
       "3  Krakow Hotel was below my expectations because...       0\n",
       "4  All the city tour guides have been excellent a...       1\n",
       "5  The bed in the Radisson Bleu was not comfortab...       0\n",
       "6  The Prague hotel should provide in-room intern...       0\n",
       "7  Michael (Tour Director) was brilliant! Thomas ...       1\n",
       "8  The entire voyage was very well done by Viking...       0\n",
       "9  Michael was excellent. The Prague hotel should...       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset \n",
    "dfData.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats and Infos\n",
    "Some info about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attributes: 2\n",
      "Name of attributes: Index(['FEEDBACK', 'RATING'], dtype='object')\n",
      "Number of rows: 28448\n",
      "Positives/Negatives: 0.5643982002249719\n"
     ]
    }
   ],
   "source": [
    "print('Number of attributes:', dfData.shape[1])\n",
    "print('Name of attributes:', dfData.columns)\n",
    "print('Number of rows:', dfData.shape[0])\n",
    "print('Positives/Negatives:', dfData['RATING'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feacture Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Feature Vector\n",
    "Machine learning requires that features (input) correlates with target class (output). For that reason, we need to define the features that we want to use for machine learning. We use words as features because they correlate with sentiments.\n",
    "\n",
    "### Result\n",
    "* **dfFeature**: DataFrame containing a list of features (words). It contains for each feature the frequency and avg. sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# MODIFY THIS METHOD TO WIN\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# HINT: e.g., TF/IDF\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "\n",
    "# counts the tokens in a list of tokens.\n",
    "def countTokens(tokens):\n",
    "    results = {}\n",
    "\n",
    "    for token in tokens:\n",
    "        if token not in results:\n",
    "            results[token] = 1\n",
    "        else:\n",
    "            results[token] = results[token] + 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# MODIFY THIS METHOD TO WIN\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# HINT: stopwords, lemmatization, stemming, named entity, lowercase, word combination (e.g, 'not good'), adjectives, etc. \n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "\n",
    "# extract features from a text\n",
    "def extractTokens(strText):\n",
    "    result = []\n",
    "    # features = tokenizer.tokenize(strText)\n",
    "    result = re.split('\\s', strText)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureColumns = ['feature', 'positives', 'negatives']\n",
    "dfFeatures = pd.DataFrame(columns=featureColumns)\n",
    "colFeedback = 'FEEDBACK'\n",
    "colRating = 'RATING'\n",
    "\n",
    "features = {}\n",
    "for index, row in dfData.iterrows(): #dfData[1:1000].iterrows():#\n",
    "    # get feedback\n",
    "    feedback = dfData.iloc[index][colFeedback]\n",
    "    rating = dfData.iloc[index][colRating]\n",
    "    \n",
    "    # analyze feedback\n",
    "    tokens = extractTokens(str(feedback))\n",
    "    featurecount = countTokens(tokens)\n",
    "    \n",
    "    # add to feature list\n",
    "    for feature in featurecount.keys():\n",
    "        if feature not in features:\n",
    "            features[feature] = {'positives': 0, 'negatives': 0}\n",
    "        if rating == 0:\n",
    "            features[feature]['negatives'] = features[feature]['negatives'] + 1\n",
    "        elif rating != 0:\n",
    "            features[feature]['positives'] = features[feature]['positives'] + 1   \n",
    "          \n",
    "# create and beautify\n",
    "dfFeatures = pd.DataFrame.from_dict(features, orient='index')\n",
    "dfFeatures = dfFeatures.reset_index()\n",
    "dfFeatures = dfFeatures.rename({'index':'feature'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results haven been written to  ./result/allfeatures.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>positives</th>\n",
       "      <th>negatives</th>\n",
       "      <th>support</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45865</th>\n",
       "      <td>the</td>\n",
       "      <td>5730</td>\n",
       "      <td>5251</td>\n",
       "      <td>10981</td>\n",
       "      <td>0.521810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48319</th>\n",
       "      <td>was</td>\n",
       "      <td>5547</td>\n",
       "      <td>4053</td>\n",
       "      <td>9600</td>\n",
       "      <td>0.577812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23663</th>\n",
       "      <td>and</td>\n",
       "      <td>5551</td>\n",
       "      <td>3541</td>\n",
       "      <td>9092</td>\n",
       "      <td>0.610537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46351</th>\n",
       "      <td>to</td>\n",
       "      <td>3753</td>\n",
       "      <td>5029</td>\n",
       "      <td>8782</td>\n",
       "      <td>0.427351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38601</th>\n",
       "      <td>of</td>\n",
       "      <td>3174</td>\n",
       "      <td>3305</td>\n",
       "      <td>6479</td>\n",
       "      <td>0.489890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22700</th>\n",
       "      <td>a</td>\n",
       "      <td>3210</td>\n",
       "      <td>3102</td>\n",
       "      <td>6312</td>\n",
       "      <td>0.508555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34812</th>\n",
       "      <td>in</td>\n",
       "      <td>2518</td>\n",
       "      <td>3412</td>\n",
       "      <td>5930</td>\n",
       "      <td>0.424621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>3063</td>\n",
       "      <td>2611</td>\n",
       "      <td>5674</td>\n",
       "      <td>0.539831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11702</th>\n",
       "      <td>I</td>\n",
       "      <td>2612</td>\n",
       "      <td>2342</td>\n",
       "      <td>4954</td>\n",
       "      <td>0.527251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48604</th>\n",
       "      <td>were</td>\n",
       "      <td>3089</td>\n",
       "      <td>1798</td>\n",
       "      <td>4887</td>\n",
       "      <td>0.632085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32437</th>\n",
       "      <td>for</td>\n",
       "      <td>1925</td>\n",
       "      <td>2418</td>\n",
       "      <td>4343</td>\n",
       "      <td>0.443242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38744</th>\n",
       "      <td>on</td>\n",
       "      <td>1855</td>\n",
       "      <td>2459</td>\n",
       "      <td>4314</td>\n",
       "      <td>0.429995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47852</th>\n",
       "      <td>very</td>\n",
       "      <td>2763</td>\n",
       "      <td>1429</td>\n",
       "      <td>4192</td>\n",
       "      <td>0.659113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>-</td>\n",
       "      <td>1868</td>\n",
       "      <td>2204</td>\n",
       "      <td>4072</td>\n",
       "      <td>0.458743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20736</th>\n",
       "      <td>The</td>\n",
       "      <td>2295</td>\n",
       "      <td>1741</td>\n",
       "      <td>4036</td>\n",
       "      <td>0.568632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38386</th>\n",
       "      <td>not</td>\n",
       "      <td>852</td>\n",
       "      <td>3098</td>\n",
       "      <td>3950</td>\n",
       "      <td>0.215696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33810</th>\n",
       "      <td>have</td>\n",
       "      <td>1427</td>\n",
       "      <td>2259</td>\n",
       "      <td>3686</td>\n",
       "      <td>0.387141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46533</th>\n",
       "      <td>tour</td>\n",
       "      <td>1681</td>\n",
       "      <td>1833</td>\n",
       "      <td>3514</td>\n",
       "      <td>0.478372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48449</th>\n",
       "      <td>we</td>\n",
       "      <td>1261</td>\n",
       "      <td>1771</td>\n",
       "      <td>3032</td>\n",
       "      <td>0.415897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48902</th>\n",
       "      <td>with</td>\n",
       "      <td>1568</td>\n",
       "      <td>1289</td>\n",
       "      <td>2857</td>\n",
       "      <td>0.548827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  positives  negatives  support  sentiment\n",
       "45865     the       5730       5251    10981   0.521810\n",
       "48319     was       5547       4053     9600   0.577812\n",
       "23663     and       5551       3541     9092   0.610537\n",
       "46351      to       3753       5029     8782   0.427351\n",
       "38601      of       3174       3305     6479   0.489890\n",
       "22700       a       3210       3102     6312   0.508555\n",
       "34812      in       2518       3412     5930   0.424621\n",
       "0                   3063       2611     5674   0.539831\n",
       "11702       I       2612       2342     4954   0.527251\n",
       "48604    were       3089       1798     4887   0.632085\n",
       "32437     for       1925       2418     4343   0.443242\n",
       "38744      on       1855       2459     4314   0.429995\n",
       "47852    very       2763       1429     4192   0.659113\n",
       "1899        -       1868       2204     4072   0.458743\n",
       "20736     The       2295       1741     4036   0.568632\n",
       "38386     not        852       3098     3950   0.215696\n",
       "33810    have       1427       2259     3686   0.387141\n",
       "46533    tour       1681       1833     3514   0.478372\n",
       "48449      we       1261       1771     3032   0.415897\n",
       "48902    with       1568       1289     2857   0.548827"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of times freature occures\n",
    "dfFeatures['support'] = dfFeatures.apply(lambda x: x['positives'] + x['negatives'], axis=1)\n",
    "\n",
    "# Compute sentiment value feature\n",
    "dfFeatures['sentiment'] = dfFeatures.apply(lambda x: x['positives'] / x['support'], axis=1)\n",
    "fnFeaturesAll = 'allfeatures.xlsx'\n",
    "writeResults(dfFeatures, fnFeaturesAll)\n",
    "\n",
    "dfFeatures.sort_values(by='support', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features 49414\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Features\", dfFeatures.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (i) DISCUSSION: How to clean up the features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExcelWorkbook = pd.read_excel(outDirectory + fnFeaturesAll, sheet_name=None)\n",
    "sheets = list(dfExcelWorkbook.keys())\n",
    "dfFeatures = dfExcelWorkbook[sheets[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Stats:\n",
      "Number of Features: 49414\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>positives</th>\n",
       "      <th>negatives</th>\n",
       "      <th>support</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3063</td>\n",
       "      <td>2611</td>\n",
       "      <td>5674</td>\n",
       "      <td>0.539831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!</td>\n",
       "      <td>63</td>\n",
       "      <td>19</td>\n",
       "      <td>82</td>\n",
       "      <td>0.768293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>!)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>!Clare</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>!Merci</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"</td>\n",
       "      <td>31</td>\n",
       "      <td>48</td>\n",
       "      <td>79</td>\n",
       "      <td>0.392405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"\"touristy\".</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\")</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\",</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\".</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"...\"</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"4\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"6\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  positives  negatives  support  sentiment\n",
       "0            NaN       3063       2611     5674   0.539831\n",
       "1              !         63         19       82   0.768293\n",
       "2             !!         14          3       17   0.823529\n",
       "3            !!!         12          4       16   0.750000\n",
       "4           !!!!          1          0        1   1.000000\n",
       "5          !!!!!          1          0        1   1.000000\n",
       "6             !)          0          1        1   0.000000\n",
       "7         !Clare          0          1        1   0.000000\n",
       "8         !Merci          1          0        1   1.000000\n",
       "9              \"         31         48       79   0.392405\n",
       "10            \"\"          0          1        1   0.000000\n",
       "11  \"\"touristy\".          1          0        1   1.000000\n",
       "12            \")          0          1        1   0.000000\n",
       "13            \",          0          1        1   0.000000\n",
       "14            \".          1          0        1   1.000000\n",
       "15         \"...\"          1          2        3   0.333333\n",
       "16           \"25          0          1        1   0.000000\n",
       "17           \"4\"          1          0        1   1.000000\n",
       "18           \"6\"          1          0        1   1.000000\n",
       "19            \"A          0          1        1   0.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Feature Stats:')\n",
    "print('Number of Features:', dfFeatures.shape[0])\n",
    "dfFeatures.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>positives</th>\n",
       "      <th>negatives</th>\n",
       "      <th>support</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45865</th>\n",
       "      <td>the</td>\n",
       "      <td>5730</td>\n",
       "      <td>5251</td>\n",
       "      <td>10981</td>\n",
       "      <td>0.521810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48319</th>\n",
       "      <td>was</td>\n",
       "      <td>5547</td>\n",
       "      <td>4053</td>\n",
       "      <td>9600</td>\n",
       "      <td>0.577812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23663</th>\n",
       "      <td>and</td>\n",
       "      <td>5551</td>\n",
       "      <td>3541</td>\n",
       "      <td>9092</td>\n",
       "      <td>0.610537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46351</th>\n",
       "      <td>to</td>\n",
       "      <td>3753</td>\n",
       "      <td>5029</td>\n",
       "      <td>8782</td>\n",
       "      <td>0.427351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38601</th>\n",
       "      <td>of</td>\n",
       "      <td>3174</td>\n",
       "      <td>3305</td>\n",
       "      <td>6479</td>\n",
       "      <td>0.489890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22700</th>\n",
       "      <td>a</td>\n",
       "      <td>3210</td>\n",
       "      <td>3102</td>\n",
       "      <td>6312</td>\n",
       "      <td>0.508555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34812</th>\n",
       "      <td>in</td>\n",
       "      <td>2518</td>\n",
       "      <td>3412</td>\n",
       "      <td>5930</td>\n",
       "      <td>0.424621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3063</td>\n",
       "      <td>2611</td>\n",
       "      <td>5674</td>\n",
       "      <td>0.539831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11702</th>\n",
       "      <td>I</td>\n",
       "      <td>2612</td>\n",
       "      <td>2342</td>\n",
       "      <td>4954</td>\n",
       "      <td>0.527251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48604</th>\n",
       "      <td>were</td>\n",
       "      <td>3089</td>\n",
       "      <td>1798</td>\n",
       "      <td>4887</td>\n",
       "      <td>0.632085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  positives  negatives  support  sentiment\n",
       "45865     the       5730       5251    10981   0.521810\n",
       "48319     was       5547       4053     9600   0.577812\n",
       "23663     and       5551       3541     9092   0.610537\n",
       "46351      to       3753       5029     8782   0.427351\n",
       "38601      of       3174       3305     6479   0.489890\n",
       "22700       a       3210       3102     6312   0.508555\n",
       "34812      in       2518       3412     5930   0.424621\n",
       "0         NaN       3063       2611     5674   0.539831\n",
       "11702       I       2612       2342     4954   0.527251\n",
       "48604    were       3089       1798     4887   0.632085"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFeatureVector = dfFeatures.sort_values(by='support', ascending=False)\n",
    "dfFeatureVector.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top-10 Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>positives</th>\n",
       "      <th>negatives</th>\n",
       "      <th>support</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36808</th>\n",
       "      <td>lunch-NO</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\"American\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>\"American</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49303</th>\n",
       "      <td>you'd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49304</th>\n",
       "      <td>you'll</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49306</th>\n",
       "      <td>you've</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"AVERAGE\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49311</th>\n",
       "      <td>you.This</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"AUTODEFESS\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49351</th>\n",
       "      <td>zippered</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  positives  negatives  support  sentiment\n",
       "36808      lunch-NO          0          1        1        0.0\n",
       "32       \"American\"          0          1        1        0.0\n",
       "31        \"American          0          1        1        0.0\n",
       "49303         you'd          0          1        1        0.0\n",
       "49304        you'll          0          1        1        0.0\n",
       "49306        you've          0          1        1        0.0\n",
       "28        \"AVERAGE\"          0          1        1        0.0\n",
       "49311      you.This          0          1        1        0.0\n",
       "27     \"AUTODEFESS\"          0          1        1        0.0\n",
       "49351      zippered          0          1        1        0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFeatureVector.sort_values(by='sentiment', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-10 Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>positives</th>\n",
       "      <th>negatives</th>\n",
       "      <th>support</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7123</th>\n",
       "      <td>Choc</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31202</th>\n",
       "      <td>excurison</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3712</th>\n",
       "      <td>ANA.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46948</th>\n",
       "      <td>tries</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>ANABELA!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41200</th>\n",
       "      <td>qualityof</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41198</th>\n",
       "      <td>quality.I</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>ANABELA)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38614</th>\n",
       "      <td>ofered</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>ANABELLA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  positives  negatives  support  sentiment\n",
       "7123        Choc          1          0        1        1.0\n",
       "31202  excurison          2          0        2        1.0\n",
       "3712        ANA.          1          0        1        1.0\n",
       "46948      tries          2          0        2        1.0\n",
       "3714    ANABELA!          1          0        1        1.0\n",
       "41200  qualityof          1          0        1        1.0\n",
       "41198  quality.I          1          0        1        1.0\n",
       "3715    ANABELA)          1          0        1        1.0\n",
       "38614     ofered          2          0        2        1.0\n",
       "3716    ANABELLA          1          0        1        1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFeatureVector.sort_values(by='sentiment', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 49414\n",
      "Number of selected features: 49414\n"
     ]
    }
   ],
   "source": [
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# MODIFY THIS METHOD TO WIN\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# HINT: e.g., remove rare features, remove irrelevant features\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "\n",
    "def selectFeatures(dfFeatures):\n",
    "    print(\"Number of features:\",dfFeatures.shape[0])\n",
    "    result = dfFeatures\n",
    "    # result = dfFeatures[dfFeatures.support > 10]\n",
    "    \n",
    "    print(\"Number of selected features:\", result.shape[0])\n",
    "    return result\n",
    "    \n",
    "dfSelectedFeatures = selectFeatures(dfFeatureVector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Trainingset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An instance from a text is used to train a machine learning model or to classify the text. The instance is a vector representation of a text based on the given feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createInstance(strText, dfFeatures=dfFeatureVector):\n",
    "    result = []\n",
    "    \n",
    "    for feature in dfFeatureVector['feature']:\n",
    "        if (str(feature) in strText):\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = []\n",
    "trainSetLabels = []\n",
    "for index, row in dfData[0:100].iterrows():\n",
    "    instance = createInstance(str(row['FEEDBACK']))\n",
    "    trainSet.append(instance)\n",
    "    trainSetLabels.append(row['RATING'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  ...]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check result\n",
    "trainSet[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X2TrainInstances = SelectKBest(chi2, k=10).fit_transform(trainSet, trainSetLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = dok_matrix(trainSet)\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "myDecisionTree = DecisionTreeClassifier(max_depth=5)\n",
    "classifier = myDecisionTree.fit(trainSet,trainSetLabels)\n",
    "\n",
    "# Random Forest\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# classifier = RandomForestClassifier(n_estimators=20).fit(trainSet,trainSetLabels)\n",
    "\n",
    "# Naive Bayes (NB)\n",
    "# classifier = GaussianNB().fit(trainSet,trainSetLabels)\n",
    "\n",
    "# ADA Boost\n",
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "#classifier = AdaBoostClassifier(n_estimators=200).fit(m,trainSetLabels)\n",
    "\n",
    "# Support Vector Machines (SVM)\n",
    "# classifier = SVC().fit(m,trainSetLabels)\n",
    "\n",
    "# Neural Network (NN)\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#classifier = MLPClassifier(alpha=1).fit(trainSet,trainSetLabels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(trainSet,trainSetLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score per fold: [0.72727273 0.90909091 0.72727273 0.90909091 0.8        0.4\n",
      " 0.77777778 0.44444444 0.77777778 0.77777778]\n",
      "Avg. Score: 0.7250505050505051\n",
      "Precision: 0.8196428571428571\n",
      "Recall: 0.7785714285714286\n",
      "F1: 0.8082950382950382\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(myDecisionTree, trainSet, trainSetLabels, cv=10)\n",
    "print('Score per fold:', score)\n",
    "print('Avg. Score:', score.mean())\n",
    "\n",
    "Precision_score = cross_val_score(myDecisionTree, trainSet, trainSetLabels, cv=10, scoring='precision')\n",
    "print('Precision:', Precision_score.mean())\n",
    "Recall_score = cross_val_score(myDecisionTree, trainSet, trainSetLabels, cv=10, scoring='recall')\n",
    "print('Recall:', Recall_score.mean())\n",
    "F1_score = cross_val_score(myDecisionTree, trainSet, trainSetLabels, cv=10, scoring='f1')\n",
    "print('F1:', F1_score.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = myDecisionTree.fit(trainSet,trainSetLabels)\n",
    "\n",
    "# Naive Bayes (NB)\n",
    "#classifier = GaussianNB().fit(trainSet,trainSetLabels)\n",
    "\n",
    "# Support Vector Machines (SVM)\n",
    "# svm = SVC()\n",
    "# classifier = svm.fit(m,trainSetLabels)\n",
    "\n",
    "# ADA Boost\n",
    "# adaBoost = AdaBoostClassifier(n_estimators=200)\n",
    "# classifier = adaBoost.fit(m,trainSetLabels)\n",
    "\n",
    "# Random Forest\n",
    "# randomForest = RandomForestClassifier(n_estimat§ors=20)\n",
    "# classifier = randomForest.fit(trainSet,trainSetLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI says GOOD :\t The bed in the Radisson Bleu was not comfortable. However, the breakfast was excellent with good food and excellent service. WE had a wonderful time and will travel with Viking again\n",
      "AI says GOOD :\t The Prague hotel should provide in-room internet. The krakow hotel was well situated but was \"tired\" in appearance & furnishings. Breakfast at all hotels was outstanding.\n",
      "AI says GOOD :\t Would like to have spent longer at Lamego\n",
      "AI says GOOD :\t Would have been nice to have had a box lunch since tour left @ 7:15 am & did not return until 2:30\n"
     ]
    }
   ],
   "source": [
    "for index, row in dfData[0:100].iterrows():\n",
    "    feedback = str(row['FEEDBACK'])\n",
    "    instance = [createInstance(feedback)]\n",
    "    predictedSentiment = classifier.predict(instance)\n",
    "    \n",
    "    if (predictedSentiment != row['RATING']):\n",
    "        sentiment = 'BAD'\n",
    "        if predictedSentiment == 1:\n",
    "            sentiment = 'GOOD'\n",
    "        print(\"AI says\", sentiment, \":\\t\",feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
