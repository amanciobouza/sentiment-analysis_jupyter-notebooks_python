{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "##Â Learning Objectives:\n",
    "1. How to prepare data for machine learning, i.e., feature selection\n",
    "1. How to learn a machine learning classifier\n",
    "1. How to learn a machine learning classifier\n",
    "1. How to apply a machine learning classifier\n",
    "1. How to evaluate a machine learning classifier\n",
    "\n",
    "### Process:\n",
    "1. load dataset\n",
    "1. analyzse dataset\n",
    "1. create feature vector\n",
    "1. vectorize data\n",
    "1. learn machine learning classifier\n",
    "1. evaluate classifier\n",
    "1. apply machine learning classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/bouza/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pytz>=2011k in /Users/bouza/anaconda3/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Users/bouza/anaconda3/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: python-dateutil>=2 in /Users/bouza/anaconda3/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: six>=1.5 in /Users/bouza/anaconda3/lib/python3.6/site-packages (from python-dateutil>=2->pandas)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: xlrd in /Users/bouza/anaconda3/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: nltk in /Users/bouza/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: six in /Users/bouza/anaconda3/lib/python3.6/site-packages (from nltk)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sklearn in /Users/bouza/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: scikit-learn in /Users/bouza/anaconda3/lib/python3.6/site-packages (from sklearn)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: openpyxl in /Users/bouza/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: jdcal in /Users/bouza/anaconda3/lib/python3.6/site-packages (from openpyxl)\n",
      "Requirement already satisfied: et_xmlfile in /Users/bouza/anaconda3/lib/python3.6/site-packages (from openpyxl)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scipy in /Users/bouza/anaconda3/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install xlrd\n",
    "!{sys.executable} -m pip install nltk\n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "!{sys.executable} -m pip install scipy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################\n",
    "# Required\n",
    "################################\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "\n",
    "# Feature Creation\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#tokenizer = RegexpTokenizer(r'\\w+[-]?\\w+')\n",
    "\n",
    "# Machine Learning Algorithms\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# More at http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "################################\n",
    "# Optional\n",
    "################################\n",
    "import re #RegEx\n",
    "\n",
    "# Improve feature creation\n",
    "## Natural Language Processing module\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Improve feature selection\n",
    "import sklearn\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Machine Learning\n",
    "import scipy\n",
    "from scipy.sparse import dok_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version check:\n",
      "--------------\n",
      "Pandas v 0.22.0\n",
      "NLTK v 3.2.4\n",
      "SKLearn v 0.19.1\n"
     ]
    }
   ],
   "source": [
    "# Checking versions\n",
    "print('Version check:\\n--------------')\n",
    "print('Pandas v',pd.__version__)\n",
    "print('NLTK v',nltk.__version__)\n",
    "print('SKLearn v',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to download NLTK packages\n",
    "Replace *URL*, *USERNAME*, and *PASSWORD* if you need to configure a proxy.\n",
    "\n",
    "Then, uncomment the lines and run it.\n",
    "\n",
    "*Please note that a separate windows will popup. Select the appropriate package.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.set_proxy('http://gate-zrh-os.swissre.com:8080', ('<USERNAME>', '<PASSWORD>'))\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving DataFrame as EXCEL for review\n",
    "def writeResults(dfResults, sFilename, sPrefix='', sPostfix=''):\n",
    "    fnOut = sFilename\n",
    "    if sPrefix:\n",
    "        fnOut = sPrefix + fnOut\n",
    "    if sPostfix:\n",
    "        fnOut = fnOut + sPostfix\n",
    "        \n",
    "    filepath = outDirectory + fnOut\n",
    "    dfResults.to_excel(filepath)\n",
    "    print('Results haven been written to ', filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath to dataset\n",
    "fpDataset = './data/customer-feedback_full_cleaned_1000.xlsx'\n",
    "\n",
    "#Load Excel file into a DataFrame\n",
    "dfExcelWorkbook = pd.read_excel(fpDataset, sheet_name=None)\n",
    "sheets = list(dfExcelWorkbook.keys())\n",
    "dfData = dfExcelWorkbook[sheets[0]]\n",
    "\n",
    "# Prepare directory to output results\n",
    "outDirectory = './result/'\n",
    "if not os.path.exists(outDirectory):\n",
    "    os.makedirs(outDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEEDBACK</th>\n",
       "      <th>RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never got clean glasses in Warsaw either.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The bed in the Radisson Bleu was not comfortab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michael was an excellent tour director. He wen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Krakow Hotel was below my expectations because...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All the city tour guides have been excellent a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The bed in the Radisson Bleu was not comfortab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Prague hotel should provide in-room intern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Michael (Tour Director) was brilliant! Thomas ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The entire voyage was very well done by Viking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Michael was excellent. The Prague hotel should...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            FEEDBACK  RATING\n",
       "0          never got clean glasses in Warsaw either.       0\n",
       "1  The bed in the Radisson Bleu was not comfortab...       1\n",
       "2  Michael was an excellent tour director. He wen...       1\n",
       "3  Krakow Hotel was below my expectations because...       0\n",
       "4  All the city tour guides have been excellent a...       1\n",
       "5  The bed in the Radisson Bleu was not comfortab...       0\n",
       "6  The Prague hotel should provide in-room intern...       0\n",
       "7  Michael (Tour Director) was brilliant! Thomas ...       1\n",
       "8  The entire voyage was very well done by Viking...       0\n",
       "9  Michael was excellent. The Prague hotel should...       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset \n",
    "dfData.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats and Infos\n",
    "Some info about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attributes: 2\n",
      "Name of attributes: Index(['FEEDBACK', 'RATING'], dtype='object')\n",
      "Number of rows: 1000\n",
      "Positives/Negatives: 0.539\n"
     ]
    }
   ],
   "source": [
    "print('Number of attributes:', dfData.shape[1])\n",
    "print('Name of attributes:', dfData.columns)\n",
    "print('Number of rows:', dfData.shape[0])\n",
    "print('Positives/Negatives:', dfData['RATING'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feacture Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Feature Vector\n",
    "Machine learning requires that features (input) correlates with target class (output). For that reason, we need to define the features that we want to use for machine learning. We use words as features because they correlate with sentiments.\n",
    "\n",
    "### Result\n",
    "* **dfFeature**: DataFrame containing a list of features (words). It contains for each feature the frequency and avg. sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# MODIFY THIS METHOD TO WIN\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# HINT: e.g., TF/IDF\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "\n",
    "# counts the tokens in a list of tokens.\n",
    "def countTokens(tokens):\n",
    "    results = {}\n",
    "\n",
    "    for token in tokens:\n",
    "        if token not in results:\n",
    "            results[token] = 1\n",
    "        else:\n",
    "            results[token] = results[token] + 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# MODIFY THIS METHOD TO WIN\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "#Â HINT: stopwords, lemmatization, stemming, named entity, lowercase, word combination (e.g, 'not good'), adjectives, etc. \n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "\n",
    "# extract features from a text\n",
    "def extractTokens(strText):\n",
    "    result = []\n",
    "    # features = tokenizer.tokenize(strText)\n",
    "    result = re.split('\\s', strText)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureColumns = ['feature', 'positives', 'negatives']\n",
    "dfFeatures = pd.DataFrame(columns=featureColumns)\n",
    "colFeedback = 'FEEDBACK'\n",
    "colRating = 'RATING'\n",
    "\n",
    "features = {}\n",
    "for index, row in dfData.iterrows(): #dfData[1:1000].iterrows():#\n",
    "    # get feedback\n",
    "    feedback = dfData.iloc[index][colFeedback]\n",
    "    rating = dfData.iloc[index][colRating]\n",
    "    \n",
    "    # analyze feedback\n",
    "    tokens = extractTokens(str(feedback))\n",
    "    featurecount = countTokens(tokens)\n",
    "    \n",
    "    # add to feature list\n",
    "    for feature in featurecount.keys():\n",
    "        if feature not in features:\n",
    "            features[feature] = {'positives': 0, 'negatives': 0}\n",
    "        if rating == 0:\n",
    "            features[feature]['negatives'] = features[feature]['negatives'] + 1\n",
    "        elif rating != 0:\n",
    "            features[feature]['positives'] = features[feature]['positives'] + 1   \n",
    "          \n",
    "# create and beautify\n",
    "dfFeatures = pd.DataFrame.from_dict(features, orient='index')\n",
    "dfFeatures = dfFeatures.reset_index()\n",
    "dfFeatures = dfFeatures.rename({'index':'feature'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results haven been written to  ./result/allfeatures.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>positives</th>\n",
       "      <th>negatives</th>\n",
       "      <th>support</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4187</th>\n",
       "      <td>the</td>\n",
       "      <td>203</td>\n",
       "      <td>205</td>\n",
       "      <td>408</td>\n",
       "      <td>0.497549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>to</td>\n",
       "      <td>135</td>\n",
       "      <td>233</td>\n",
       "      <td>368</td>\n",
       "      <td>0.366848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>was</td>\n",
       "      <td>202</td>\n",
       "      <td>165</td>\n",
       "      <td>367</td>\n",
       "      <td>0.550409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>and</td>\n",
       "      <td>200</td>\n",
       "      <td>134</td>\n",
       "      <td>334</td>\n",
       "      <td>0.598802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>of</td>\n",
       "      <td>132</td>\n",
       "      <td>126</td>\n",
       "      <td>258</td>\n",
       "      <td>0.511628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>a</td>\n",
       "      <td>123</td>\n",
       "      <td>134</td>\n",
       "      <td>257</td>\n",
       "      <td>0.478599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>in</td>\n",
       "      <td>98</td>\n",
       "      <td>144</td>\n",
       "      <td>242</td>\n",
       "      <td>0.404959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>113</td>\n",
       "      <td>99</td>\n",
       "      <td>212</td>\n",
       "      <td>0.533019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4449</th>\n",
       "      <td>very</td>\n",
       "      <td>130</td>\n",
       "      <td>53</td>\n",
       "      <td>183</td>\n",
       "      <td>0.710383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>-</td>\n",
       "      <td>87</td>\n",
       "      <td>83</td>\n",
       "      <td>170</td>\n",
       "      <td>0.511765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>not</td>\n",
       "      <td>31</td>\n",
       "      <td>138</td>\n",
       "      <td>169</td>\n",
       "      <td>0.183432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>were</td>\n",
       "      <td>96</td>\n",
       "      <td>69</td>\n",
       "      <td>165</td>\n",
       "      <td>0.581818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>for</td>\n",
       "      <td>60</td>\n",
       "      <td>93</td>\n",
       "      <td>153</td>\n",
       "      <td>0.392157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293</th>\n",
       "      <td>on</td>\n",
       "      <td>56</td>\n",
       "      <td>95</td>\n",
       "      <td>151</td>\n",
       "      <td>0.370861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>I</td>\n",
       "      <td>67</td>\n",
       "      <td>81</td>\n",
       "      <td>148</td>\n",
       "      <td>0.452703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>have</td>\n",
       "      <td>59</td>\n",
       "      <td>89</td>\n",
       "      <td>148</td>\n",
       "      <td>0.398649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4299</th>\n",
       "      <td>tour</td>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "      <td>143</td>\n",
       "      <td>0.510490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>The</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>135</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4542</th>\n",
       "      <td>we</td>\n",
       "      <td>49</td>\n",
       "      <td>70</td>\n",
       "      <td>119</td>\n",
       "      <td>0.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>with</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>109</td>\n",
       "      <td>0.513761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  positives  negatives  support  sentiment\n",
       "4187     the        203        205      408   0.497549\n",
       "4271      to        135        233      368   0.366848\n",
       "4523     was        202        165      367   0.550409\n",
       "1234     and        200        134      334   0.598802\n",
       "3275      of        132        126      258   0.511628\n",
       "1093       a        123        134      257   0.478599\n",
       "2728      in         98        144      242   0.404959\n",
       "0                   113         99      212   0.533019\n",
       "4449    very        130         53      183   0.710383\n",
       "91         -         87         83      170   0.511765\n",
       "3252     not         31        138      169   0.183432\n",
       "4563    were         96         69      165   0.581818\n",
       "2419     for         60         93      153   0.392157\n",
       "3293      on         56         95      151   0.370861\n",
       "564        I         67         81      148   0.452703\n",
       "2596    have         59         89      148   0.398649\n",
       "4299    tour         73         70      143   0.510490\n",
       "959      The         75         60      135   0.555556\n",
       "4542      we         49         70      119   0.411765\n",
       "4599    with         56         53      109   0.513761"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of times freature occures\n",
    "dfFeatures['support'] = dfFeatures.apply(lambda x: x['positives'] + x['negatives'], axis=1)\n",
    "\n",
    "# Compute sentiment value feature\n",
    "dfFeatures['sentiment'] = dfFeatures.apply(lambda x: x['positives'] / x['support'], axis=1)\n",
    "fnFeaturesAll = 'allfeatures.xlsx'\n",
    "writeResults(dfFeatures, fnFeaturesAll)\n",
    "\n",
    "dfFeatures.sort_values(by='support', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features 4665\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Features\", dfFeatures.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (i) DISCUSSION: How to clean up the features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExcelWorkbook = pd.read_excel(outDirectory + fnFeaturesAll, sheet_name=None)\n",
    "sheets = list(dfExcelWorkbook.keys())\n",
    "dfFeatures = dfExcelWorkbook[sheets[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Stats:\n",
      "Number of Features: 4665\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>positives</th>\n",
       "      <th>negatives</th>\n",
       "      <th>support</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "      <td>99</td>\n",
       "      <td>212</td>\n",
       "      <td>0.533019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Above</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Erdogan\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Excellent\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Manning\".</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"My</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Radisson</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Two-for-one\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"above</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"above\"/\"far</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"area\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"cute\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"far</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"farewell</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"food\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"full</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"great\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  positives  negatives  support  sentiment\n",
       "0             NaN        113         99      212   0.533019\n",
       "1               !          2          0        2   1.000000\n",
       "2              !!          1          0        1   1.000000\n",
       "3               \"          2          2        4   0.500000\n",
       "4          \"Above          0          1        1   0.000000\n",
       "5       \"Erdogan\"          0          1        1   0.000000\n",
       "6     \"Excellent\"          1          0        1   1.000000\n",
       "7      \"Manning\".          0          1        1   0.000000\n",
       "8             \"My          0          1        1   0.000000\n",
       "9       \"Radisson          0          1        1   0.000000\n",
       "10  \"Two-for-one\"          0          1        1   0.000000\n",
       "11         \"above          1          0        1   1.000000\n",
       "12   \"above\"/\"far          0          1        1   0.000000\n",
       "13         \"area\"          1          0        1   1.000000\n",
       "14         \"cute\"          0          1        1   0.000000\n",
       "15           \"far          2          0        2   1.000000\n",
       "16      \"farewell          0          1        1   0.000000\n",
       "17         \"food\"          0          1        1   0.000000\n",
       "18          \"full          0          1        1   0.000000\n",
       "19        \"great\"          1          0        1   1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Feature Stats:')\n",
    "print('Number of Features:', dfFeatures.shape[0])\n",
    "dfFeatures.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>positives</th>\n",
       "      <th>negatives</th>\n",
       "      <th>support</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45865</th>\n",
       "      <td>the</td>\n",
       "      <td>5730</td>\n",
       "      <td>5251</td>\n",
       "      <td>10981</td>\n",
       "      <td>0.521810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48319</th>\n",
       "      <td>was</td>\n",
       "      <td>5547</td>\n",
       "      <td>4053</td>\n",
       "      <td>9600</td>\n",
       "      <td>0.577812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23663</th>\n",
       "      <td>and</td>\n",
       "      <td>5551</td>\n",
       "      <td>3541</td>\n",
       "      <td>9092</td>\n",
       "      <td>0.610537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46351</th>\n",
       "      <td>to</td>\n",
       "      <td>3753</td>\n",
       "      <td>5029</td>\n",
       "      <td>8782</td>\n",
       "      <td>0.427351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38601</th>\n",
       "      <td>of</td>\n",
       "      <td>3174</td>\n",
       "      <td>3305</td>\n",
       "      <td>6479</td>\n",
       "      <td>0.489890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22700</th>\n",
       "      <td>a</td>\n",
       "      <td>3210</td>\n",
       "      <td>3102</td>\n",
       "      <td>6312</td>\n",
       "      <td>0.508555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34812</th>\n",
       "      <td>in</td>\n",
       "      <td>2518</td>\n",
       "      <td>3412</td>\n",
       "      <td>5930</td>\n",
       "      <td>0.424621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3063</td>\n",
       "      <td>2611</td>\n",
       "      <td>5674</td>\n",
       "      <td>0.539831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11702</th>\n",
       "      <td>I</td>\n",
       "      <td>2612</td>\n",
       "      <td>2342</td>\n",
       "      <td>4954</td>\n",
       "      <td>0.527251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48604</th>\n",
       "      <td>were</td>\n",
       "      <td>3089</td>\n",
       "      <td>1798</td>\n",
       "      <td>4887</td>\n",
       "      <td>0.632085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  positives  negatives  support  sentiment\n",
       "45865     the       5730       5251    10981   0.521810\n",
       "48319     was       5547       4053     9600   0.577812\n",
       "23663     and       5551       3541     9092   0.610537\n",
       "46351      to       3753       5029     8782   0.427351\n",
       "38601      of       3174       3305     6479   0.489890\n",
       "22700       a       3210       3102     6312   0.508555\n",
       "34812      in       2518       3412     5930   0.424621\n",
       "0         NaN       3063       2611     5674   0.539831\n",
       "11702       I       2612       2342     4954   0.527251\n",
       "48604    were       3089       1798     4887   0.632085"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFeatureVector = dfFeatures.sort_values(by='support', ascending=False)\n",
    "dfFeatureVector.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top-10 Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>positives</th>\n",
       "      <th>negatives</th>\n",
       "      <th>support</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36808</th>\n",
       "      <td>lunch-NO</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\"American\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>\"American</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49303</th>\n",
       "      <td>you'd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49304</th>\n",
       "      <td>you'll</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49306</th>\n",
       "      <td>you've</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"AVERAGE\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49311</th>\n",
       "      <td>you.This</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"AUTODEFESS\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49351</th>\n",
       "      <td>zippered</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  positives  negatives  support  sentiment\n",
       "36808      lunch-NO          0          1        1        0.0\n",
       "32       \"American\"          0          1        1        0.0\n",
       "31        \"American          0          1        1        0.0\n",
       "49303         you'd          0          1        1        0.0\n",
       "49304        you'll          0          1        1        0.0\n",
       "49306        you've          0          1        1        0.0\n",
       "28        \"AVERAGE\"          0          1        1        0.0\n",
       "49311      you.This          0          1        1        0.0\n",
       "27     \"AUTODEFESS\"          0          1        1        0.0\n",
       "49351      zippered          0          1        1        0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFeatureVector.sort_values(by='sentiment', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-10 Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>positives</th>\n",
       "      <th>negatives</th>\n",
       "      <th>support</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7123</th>\n",
       "      <td>Choc</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31202</th>\n",
       "      <td>excurison</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3712</th>\n",
       "      <td>ANA.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46948</th>\n",
       "      <td>tries</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>ANABELA!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41200</th>\n",
       "      <td>qualityof</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41198</th>\n",
       "      <td>quality.I</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>ANABELA)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38614</th>\n",
       "      <td>ofered</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>ANABELLA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  positives  negatives  support  sentiment\n",
       "7123        Choc          1          0        1        1.0\n",
       "31202  excurison          2          0        2        1.0\n",
       "3712        ANA.          1          0        1        1.0\n",
       "46948      tries          2          0        2        1.0\n",
       "3714    ANABELA!          1          0        1        1.0\n",
       "41200  qualityof          1          0        1        1.0\n",
       "41198  quality.I          1          0        1        1.0\n",
       "3715    ANABELA)          1          0        1        1.0\n",
       "38614     ofered          2          0        2        1.0\n",
       "3716    ANABELLA          1          0        1        1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFeatureVector.sort_values(by='sentiment', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 49414\n",
      "Number of selected features: 49414\n"
     ]
    }
   ],
   "source": [
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# MODIFY THIS METHOD TO WIN\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# HINT: e.g., remove rare features, remove irrelevant features\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "\n",
    "def selectFeatures(dfFeatures):\n",
    "    print(\"Number of features:\",dfFeatures.shape[0])\n",
    "    result = dfFeatures\n",
    "    # result = dfFeatures[dfFeatures.support > 10]\n",
    "    \n",
    "    print(\"Number of selected features:\", result.shape[0])\n",
    "    return result\n",
    "    \n",
    "dfSelectedFeatures = selectFeatures(dfFeatureVector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Trainingset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An instance from a text is used to train a machine learning model or to classify the text. The instance is a vector representation of a text based on the given feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createInstance(strText, dfFeatures=dfFeatureVector):\n",
    "    result = []\n",
    "    \n",
    "    for feature in dfFeatureVector['feature']:\n",
    "        if (str(feature) in strText):\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = []\n",
    "trainSetLabels = []\n",
    "for index, row in dfData[0:100].iterrows():\n",
    "    instance = createInstance(str(row['FEEDBACK']))\n",
    "    trainSet.append(instance)\n",
    "    trainSetLabels.append(row['RATING'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  ...]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check result\n",
    "trainSet[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X2TrainInstances = SelectKBest(chi2, k=10).fit_transform(trainSet, trainSetLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = dok_matrix(trainSet)\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "myDecisionTree = DecisionTreeClassifier(max_depth=5)\n",
    "classifier = myDecisionTree.fit(trainSet,trainSetLabels)\n",
    "\n",
    "# Random Forest\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# classifier = RandomForestClassifier(n_estimators=20).fit(trainSet,trainSetLabels)\n",
    "\n",
    "# Naive Bayes (NB)\n",
    "# classifier = GaussianNB().fit(trainSet,trainSetLabels)\n",
    "\n",
    "# ADA Boost\n",
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "#classifier = AdaBoostClassifier(n_estimators=200).fit(m,trainSetLabels)\n",
    "\n",
    "# Support Vector Machines (SVM)\n",
    "# classifier = SVC().fit(m,trainSetLabels)\n",
    "\n",
    "# Neural Network (NN)\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#classifier = MLPClassifier(alpha=1).fit(trainSet,trainSetLabels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(trainSet,trainSetLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score per fold: [0.72727273 0.90909091 0.72727273 0.90909091 0.8        0.4\n",
      " 0.77777778 0.44444444 0.77777778 0.77777778]\n",
      "Avg. Score: 0.7250505050505051\n",
      "Precision: 0.8196428571428571\n",
      "Recall: 0.7785714285714286\n",
      "F1: 0.8082950382950382\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(myDecisionTree, trainSet, trainSetLabels, cv=10)\n",
    "print('Score per fold:', score)\n",
    "print('Avg. Score:', score.mean())\n",
    "\n",
    "Precision_score = cross_val_score(myDecisionTree, trainSet, trainSetLabels, cv=10, scoring='precision')\n",
    "print('Precision:', Precision_score.mean())\n",
    "Recall_score = cross_val_score(myDecisionTree, trainSet, trainSetLabels, cv=10, scoring='recall')\n",
    "print('Recall:', Recall_score.mean())\n",
    "F1_score = cross_val_score(myDecisionTree, trainSet, trainSetLabels, cv=10, scoring='f1')\n",
    "print('F1:', F1_score.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = myDecisionTree.fit(trainSet,trainSetLabels)\n",
    "\n",
    "# Naive Bayes (NB)\n",
    "#classifier = GaussianNB().fit(trainSet,trainSetLabels)\n",
    "\n",
    "# Support Vector Machines (SVM)\n",
    "# svm = SVC()\n",
    "# classifier = svm.fit(m,trainSetLabels)\n",
    "\n",
    "# ADA Boost\n",
    "# adaBoost = AdaBoostClassifier(n_estimators=200)\n",
    "# classifier = adaBoost.fit(m,trainSetLabels)\n",
    "\n",
    "# Random Forest\n",
    "# randomForest = RandomForestClassifier(n_estimatÂ§ors=20)\n",
    "# classifier = randomForest.fit(trainSet,trainSetLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI says GOOD :\t The bed in the Radisson Bleu was not comfortable. However, the breakfast was excellent with good food and excellent service. WE had a wonderful time and will travel with Viking again\n",
      "AI says GOOD :\t The Prague hotel should provide in-room internet. The krakow hotel was well situated but was \"tired\" in appearance & furnishings. Breakfast at all hotels was outstanding.\n",
      "AI says GOOD :\t Would like to have spent longer at Lamego\n",
      "AI says GOOD :\t Would have been nice to have had a box lunch since tour left @ 7:15 am & did not return until 2:30\n"
     ]
    }
   ],
   "source": [
    "for index, row in dfData[0:100].iterrows():\n",
    "    feedback = str(row['FEEDBACK'])\n",
    "    instance = [createInstance(feedback)]\n",
    "    predictedSentiment = classifier.predict(instance)\n",
    "    \n",
    "    if (predictedSentiment != row['RATING']):\n",
    "        sentiment = 'BAD'\n",
    "        if predictedSentiment == 1:\n",
    "            sentiment = 'GOOD'\n",
    "        print(\"AI says\", sentiment, \":\\t\",feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
